python3 -m llama_cpp.server --model models/Hermes-2-Pro-Mistral-7B.Q8_0.gguf --n_gpu_layers 1000 --port 1234 --host 0.0.0.0 --n_ctx 4096
